{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.805762Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Dataset/adult.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.806930Z"
    }
   },
   "id": "ee5f92efdb4bc277",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data[data == '?'] = np.nan"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T01:58:04.812042Z",
     "start_time": "2024-06-13T01:58:04.808172Z"
    }
   },
   "id": "2718b05e9eb750d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for col in ['workclass', 'occupation', 'native-country']:\n",
    "    data[col].fillna(data[col].mode()[0], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.809535Z"
    }
   },
   "id": "dee9d263e1dbee2a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data.drop(['education'], axis = 1, inplace = True)\n",
    "data['race'].replace(['Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Black', 'Other'],'Other', inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.810677Z"
    }
   },
   "id": "ff189cdf60a6ce4c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data['income']=data['income'].map({'<=50K': 0, '>50K': 1})\n",
    "data['gender']=data['gender'].map({'Female': 0, 'Male': 1})\n",
    "data['race']=data['race'].map({'Other': 0, 'White': 1})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.811899Z"
    }
   },
   "id": "2c9cf4d370213b54",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "categorical = ['workclass', 'marital-status', 'occupation', 'relationship',\n",
    "               'race','native-country']\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical:\n",
    "    label_encoder.fit(data[col])\n",
    "    data[col] = label_encoder.transform(data[col])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.813058Z"
    }
   },
   "id": "5cae33509295206a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "train,test = train_test_split(data, test_size = 0.3, random_state = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.814199Z"
    }
   },
   "id": "664c535bb9170226",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "features_to_scale = ['workclass', 'educational-num', 'marital-status', 'occupation', 'relationship',\n",
    "                     'race', 'native-country', 'age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "\n",
    "test_CT = test.copy()\n",
    "test_CT['gender'] = 1 - test_CT['gender']\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(train[features_to_scale])\n",
    "X_test_scaled = scaler.transform(test[features_to_scale])\n",
    "X_test_CT_scaled = scaler.transform(test_CT[features_to_scale])\n",
    "\n",
    "train_scaled = pd.DataFrame(X_train_scaled, columns=features_to_scale, index=train.index)\n",
    "test_scaled = pd.DataFrame(X_test_scaled, columns=features_to_scale, index=test.index)\n",
    "test_CT_scaled = pd.DataFrame(X_test_CT_scaled, columns=features_to_scale, index=test_CT.index)\n",
    "\n",
    "train_scaled['gender'] = train['gender']\n",
    "test_scaled['gender'] = test['gender']\n",
    "test_CT_scaled['gender'] = test_CT['gender']\n",
    "\n",
    "train_scaled['income'] = train['income']\n",
    "test_scaled['income'] = test['income']\n",
    "test_CT_scaled['income'] = test_CT['income']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.815213Z"
    }
   },
   "id": "88f3be17d23adc1c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_scaled[['workclass', 'educational-num', 'marital-status', 'occupation', 'relationship',\n",
    "                     'race', 'gender', 'native-country', 'age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week','income']].to_csv('./Dataset/adult_all_train.csv', index=False)\n",
    "test_scaled[['workclass', 'educational-num', 'marital-status', 'occupation', 'relationship',\n",
    "                     'race', 'gender', 'native-country', 'age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week','income']].to_csv('./Dataset/adult_all_test.csv', index=False)\n",
    "test_CT_scaled[['workclass', 'educational-num', 'marital-status', 'occupation', 'relationship',\n",
    "                     'race', 'gender', 'native-country', 'age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week','income']].to_csv('./Dataset/adult_all_test_CT.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.815966Z"
    }
   },
   "id": "ed1587936bca8785",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_scaled[['workclass', 'marital-status', 'occupation', 'relationship',\n",
    "                     'race', 'gender', 'age', 'capital-gain', 'capital-loss', 'hours-per-week','income']].to_csv('./Dataset/adult_-1_train.csv', index=False)\n",
    "test_scaled[['workclass', 'marital-status', 'occupation', 'relationship',\n",
    "                     'race', 'gender', 'age', 'capital-gain', 'capital-loss', 'hours-per-week','income']].to_csv('./Dataset/adult_-1_test.csv', index=False)\n",
    "test_CT_scaled[['workclass', 'marital-status', 'occupation', 'relationship',\n",
    "                     'race', 'gender', 'age', 'capital-gain', 'capital-loss', 'hours-per-week','income']].to_csv('./Dataset/adult_-1_test_CT.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.816742Z"
    }
   },
   "id": "bc9163c436bf83cf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_scaled[['workclass', 'marital-status', 'relationship',\n",
    "                     'race', 'gender', 'age', 'hours-per-week','income']].to_csv('./Dataset/adult_-2_train.csv', index=False)\n",
    "test_scaled[['workclass', 'marital-status', 'relationship',\n",
    "                     'race', 'gender', 'age', 'hours-per-week','income']].to_csv('./Dataset/adult_-2_test.csv', index=False)\n",
    "test_CT_scaled[['workclass', 'marital-status', 'relationship',\n",
    "                     'race', 'gender', 'age', 'hours-per-week','income']].to_csv('./Dataset/adult_-2_test_CT.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.817496Z"
    }
   },
   "id": "fc855a080f2710c7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_scaled[[ 'marital-status', 'relationship',\n",
    "                      'gender', 'hours-per-week','income']].to_csv('./Dataset/adult_-3_train.csv', index=False)\n",
    "test_scaled[[ 'marital-status', 'relationship',\n",
    "                      'gender', 'hours-per-week','income']].to_csv('./Dataset/adult_-3_test.csv', index=False)\n",
    "test_CT_scaled[[ 'marital-status', 'relationship',\n",
    "                      'gender', 'hours-per-week','income']].to_csv('./Dataset/adult_-3_test_CT.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.818290Z"
    }
   },
   "id": "ebe3241448255b5d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_scaled.to_csv('./Dataset/adult_test_index.csv', index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.819083Z"
    }
   },
   "id": "8fb59801ce238460",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "h2o.init()\n",
    "\n",
    "train_all = h2o.upload_file(\"./Dataset/adult_all_train.csv\")\n",
    "test_all = h2o.upload_file(\"./Dataset/adult_all_test.csv\")\n",
    "test_all_CT = h2o.upload_file(\"./Dataset/adult_all_test_CT.csv\")\n",
    "\n",
    "x = train_all.columns\n",
    "y = \"income\"\n",
    "x.remove(y)\n",
    "\n",
    "train_all[y] = train_all[y].asfactor()\n",
    "test_all[y] = test_all[y].asfactor()\n",
    "test_all_CT[y] = test_all_CT[y].asfactor()\n",
    "\n",
    "aml_all = H2OAutoML(nfolds=10, max_models=10, seed=1, max_runtime_secs=120 ,include_algos = [\"GLM\", \"DeepLearning\", \"DRF\", \"GBM\", \"StackedEnsemble\"])\n",
    "aml_all.train(x=x, y=y, training_frame=train_all)\n",
    "\n",
    "lb_all = aml_all.leaderboard\n",
    "lb_all.head(rows=lb_all.nrows) \n",
    "\n",
    "###################\n",
    "\n",
    "train_1 = h2o.upload_file(\"./Dataset/adult_-1_train.csv\")\n",
    "test_1 = h2o.upload_file(\"./Dataset/adult_-1_test.csv\")\n",
    "test_1_CT = h2o.upload_file(\"./Dataset/adult_-1_test_CT.csv\")\n",
    "\n",
    "x_1 = train_1.columns\n",
    "y_1 = \"income\"\n",
    "x_1.remove(y_1)\n",
    "\n",
    "train_1[y] = train_1[y].asfactor()\n",
    "test_1[y] = test_1[y].asfactor()\n",
    "test_1_CT[y] = test_1_CT[y].asfactor()\n",
    "\n",
    "aml_1 = H2OAutoML(nfolds=10, max_models=10, seed=1, max_runtime_secs=120 ,include_algos = [\"GLM\", \"DeepLearning\", \"DRF\", \"GBM\", \"StackedEnsemble\"])\n",
    "aml_1.train(x=x_1, y=y_1, training_frame=train_1)\n",
    "\n",
    "lb_1 = aml_1.leaderboard\n",
    "lb_1.head(rows=lb_1.nrows) \n",
    "\n",
    "###################\n",
    "\n",
    "train_2 = h2o.upload_file(\"./Dataset/adult_-2_train.csv\")\n",
    "test_2 = h2o.upload_file(\"./Dataset/adult_-2_test.csv\")\n",
    "test_2_CT = h2o.upload_file(\"./Dataset/adult_-2_test_CT.csv\")\n",
    "\n",
    "x_2 = train_2.columns\n",
    "y_2 = \"income\"\n",
    "x_2.remove(y_2)\n",
    "\n",
    "train_2[y] = train_2[y].asfactor()\n",
    "test_2[y] = test_2[y].asfactor()\n",
    "test_2_CT[y] = test_2_CT[y].asfactor()\n",
    "\n",
    "aml_2 = H2OAutoML(nfolds=10, max_models=10, seed=1, max_runtime_secs=120 ,include_algos = [\"GLM\", \"DeepLearning\", \"DRF\", \"GBM\", \"StackedEnsemble\"])\n",
    "aml_2.train(x=x_2, y=y_2, training_frame=train_2)\n",
    "\n",
    "lb_2 = aml_2.leaderboard\n",
    "lb_2.head(rows=lb_2.nrows) \n",
    "\n",
    "###################\n",
    "\n",
    "train_3 = h2o.upload_file(\"./Dataset/adult_-3_train.csv\")\n",
    "test_3 = h2o.upload_file(\"./Dataset/adult_-3_test.csv\")\n",
    "test_3_CT = h2o.upload_file(\"./Dataset/adult_-3_test_CT.csv\")\n",
    "\n",
    "x_3 = train_3.columns\n",
    "y_3 = \"income\"\n",
    "x_3.remove(y_3)\n",
    "\n",
    "train_3[y] = train_3[y].asfactor()\n",
    "test_3[y] = test_3[y].asfactor()\n",
    "test_3_CT[y] = test_3_CT[y].asfactor()\n",
    "\n",
    "aml_3 = H2OAutoML(nfolds=10, max_models=10, seed=1, max_runtime_secs=120 ,include_algos = [\"GLM\", \"DeepLearning\", \"DRF\", \"GBM\", \"StackedEnsemble\"])\n",
    "aml_3.train(x=x_3, y=y_3, training_frame=train_3)\n",
    "\n",
    "lb_3 = aml_3.leaderboard\n",
    "lb_3.head(rows=lb_3.nrows) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.819892Z"
    }
   },
   "id": "1ea9b28cfa8a231f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "h2o.export_file(lb_all, path = \"./leadboard_all.csv\", force = True)\n",
    "h2o.export_file(lb_1, path = \"./leadboard_-1.csv\", force = True)\n",
    "h2o.export_file(lb_2, path = \"./leadboard_-2.csv\", force = True)\n",
    "h2o.export_file(lb_3, path = \"./leadboard_-3.csv\", force = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.820715Z"
    }
   },
   "id": "59982a46630f4e88",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "lb_all = pd.read_csv(\"./leadboard_all.csv\")\n",
    "lb_1 = pd.read_csv(\"./leadboard_-1.csv\")\n",
    "lb_2 = pd.read_csv(\"./leadboard_-2.csv\")\n",
    "lb_3 = pd.read_csv(\"./leadboard_-3.csv\")\n",
    "\n",
    "combined_df = pd.concat([lb_all, lb_1, lb_2, lb_3], ignore_index=True)\n",
    "\n",
    "combined_df.to_csv(\"./leadboard.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.821536Z"
    }
   },
   "id": "ee96584b4e7cc0f2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = './leadboard_all.csv'  \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extracting the first column which contains the model names\n",
    "model_names = data.iloc[:, 0].tolist()\n",
    "\n",
    "# Loop through each model name, retrieve the model, and save it\n",
    "for model_name in model_names:\n",
    "    model = h2o.get_model(model_name)\n",
    "    h2o.save_model(model=model, path=\"./Adult_Model/\", force=True)\n",
    "    \n",
    "    preds = model.predict(test_all)\n",
    "    preds_CT = model.predict(test_all_CT)\n",
    "\n",
    "    h2o.export_file(preds, path = f\"./Adult_Res/{model_name}.csv\", force = True)\n",
    "    h2o.export_file(preds_CT, path = f\"./Adult_Res/{model_name}_CT.csv\", force = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.822324Z"
    }
   },
   "id": "96ee3de300166c8f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = './leadboard_-1.csv'  \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extracting the first column which contains the model names\n",
    "model_names = data.iloc[:, 0].tolist()\n",
    "\n",
    "# Loop through each model name, retrieve the model, and save it\n",
    "for model_name in model_names:\n",
    "    model = h2o.get_model(model_name)\n",
    "    h2o.save_model(model=model, path=\"./Adult_Model/\", force=True)\n",
    "    \n",
    "    preds = model.predict(test_1)\n",
    "    preds_CT = model.predict(test_1_CT)\n",
    "\n",
    "    h2o.export_file(preds, path = f\"./Adult_Res/{model_name}.csv\", force = True)\n",
    "    h2o.export_file(preds_CT, path = f\"./Adult_Res/{model_name}_CT.csv\", force = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.823103Z"
    }
   },
   "id": "b91bdf6b3356ec5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = './leadboard_-2.csv'  \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extracting the first column which contains the model names\n",
    "model_names = data.iloc[:, 0].tolist()\n",
    "\n",
    "# Loop through each model name, retrieve the model, and save it\n",
    "for model_name in model_names:\n",
    "    model = h2o.get_model(model_name)\n",
    "    h2o.save_model(model=model, path=\"./Adult_Model/\", force=True)\n",
    "    \n",
    "    preds = model.predict(test_2)\n",
    "    preds_CT = model.predict(test_2_CT)\n",
    "\n",
    "    h2o.export_file(preds, path = f\"./Adult_Res/{model_name}.csv\", force = True)\n",
    "    h2o.export_file(preds_CT, path = f\"./Adult_Res/{model_name}_CT.csv\", force = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.823910Z"
    }
   },
   "id": "c415e6cc738c8db6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = './leadboard_-3.csv'  \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extracting the first column which contains the model names\n",
    "model_names = data.iloc[:, 0].tolist()\n",
    "\n",
    "# Loop through each model name, retrieve the model, and save it\n",
    "for model_name in model_names:\n",
    "    model = h2o.get_model(model_name)\n",
    "    h2o.save_model(model=model, path=\"./Adult_Model/\", force=True)\n",
    "    \n",
    "    preds = model.predict(test_3)\n",
    "    preds_CT = model.predict(test_3_CT)\n",
    "\n",
    "    h2o.export_file(preds, path = f\"./Adult_Res/{model_name}.csv\", force = True)\n",
    "    h2o.export_file(preds_CT, path = f\"./Adult_Res/{model_name}_CT.csv\", force = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.824706Z"
    }
   },
   "id": "5fcc447594206e91",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "CT_res_all = pd.DataFrame()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_path = './leadboard.csv'  \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "df = pd.read_csv('./Dataset/adult_test_index.csv')\n",
    "first_column = df.iloc[:, 0]\n",
    "\n",
    "# Extracting the first column which contains the model names\n",
    "model_names = data.iloc[:, 0].tolist()\n",
    "\n",
    "# Loop through each model name, retrieve the model, and save it\n",
    "for model_name in model_names: \n",
    "    # Load the files\n",
    "    model_ct = pd.read_csv(f'./Adult_Res/{model_name}_CT.csv')\n",
    "    model = pd.read_csv(f'./Adult_Res/{model_name}.csv')\n",
    "    CT_res = 1-((model_ct['p0'] - model['p0']).abs())\n",
    "    CT_res_rounded = CT_res.round(5)\n",
    "    \n",
    "    CT_res_all[f'{model_name}'] = CT_res_rounded\n",
    "\n",
    "\n",
    "CT_res_all.insert(0, 'ID', first_column)\n",
    "\n",
    "output_path = './Audlt_Pij.csv'\n",
    "CT_res_all.to_csv(output_path, index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-13T01:58:04.825777Z"
    }
   },
   "id": "d6aa167fe535604b",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
